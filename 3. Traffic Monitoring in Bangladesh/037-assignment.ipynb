{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<p>\n",
    "  <b>AI Lab: Deep Learning for Computer Vision</b><br>\n",
    "  <b><a href=\"https://www.wqu.edu/\">WorldQuant University</a></b>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"alert alert-danger\" role=\"alert\">\n",
    "  <p>\n",
    "    <center><b>Usage Guidelines</b></center>\n",
    "  </p>\n",
    "  <p>\n",
    "    This notebook can only be used on the WorldQuant University platform. It is not licensed for personal use or for use on any other platform.\n",
    "  </p>\n",
    "  <p>\n",
    "    You <b>cannot</b>:\n",
    "    <ul>\n",
    "      <li><span style=\"color: red\">✗</span> Download this notebook</li>\n",
    "      <li><span style=\"color: red\">✗</span> Show this notebook to friends or colleagues</li>\n",
    "      <li><span style=\"color: red\">✗</span> Post this notebook in public or private repositories</li>\n",
    "      <li><span style=\"color: red\">✗</span> Upload this notebook (or screenshots of it) to other websites, including websites for study resources</li>\n",
    "    </ul>\n",
    "  </p>\n",
    "  <p>\n",
    "    Failure to follow these guidelines is a violation of your terms of service and will lead to your expulsion from WorldQuant University and the revocation your certificate.\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.7. Istanbul Traffic Object Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you need to import the libraries you'll need. You can also import them as you find them necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import shutil\n",
    "import xml.etree.ElementTree as ET\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import yaml\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since GPUs are available on your machine, make sure you handle placing the tensors to the proper device."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3.7.1:** Check the availability of GPUs on this machine and determine the correct device name. Store the device name in the variable `device`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = ...\n",
    "print(f\"Using {device} device.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bounding box data is provided using the XML file format. Unfortunately, both the images and XML files are in the same directory, `istanbul_traffic/train`. We'll need rearrange the files and directories in the form we'll need later. Let's take a peek at the current directory hierarchy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree istanbul_traffic --filelimit=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3.7.2:** Create a variable for the train directory using `pathlib` syntax, `istanbul_traffic/train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "istanbul_dir = ...\n",
    "\n",
    "print(\"Training data directory:\", istanbul_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There should be one XML file for each JPG image. The corresponding XML and JPG share the same filename except for the file extension. E.g., `0ab6f274892b9b370e6441886b2d7b9d.jpg` and `0ab6f274892b9b370e6441886b2d7b9d.xml` belong together. We should verify that each training image has a corresponding XML file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3.7.3:** Create a variable that counts how many files have the same base name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_extension_counts = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"Number of files with 0ab6f274892b9b370e6441886b2d7b9d basename: {file_extension_counts['0ab6f274892b9b370e6441886b2d7b9d']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3.7.4:** Check that all of the values in `file_extension_counts` are 2.  An easy way to do this is to pass all of the values into a `set` object. Submit all the unique counts to the grader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_counts = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the format of the XML data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xml_filepath = istanbul_dir / \"0ab6f274892b9b370e6441886b2d7b9d.xml\"\n",
    "!head -n 25 $xml_filepath"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily for us, the XML data has the bounding box data in the format that YOLO expects. No need to transform those values! However, we'll still need to convert those XML files in text files where every line represents an object in `class_index x_center y_center width height` format. It's time to turn our attention to getting things ready."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3.7.5:** Finish the function below that returns a list of the bounding box data. The part you will need to finish is inside the `for` loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_annotations(f):\n",
    "    \"\"\"Parse all of the objects in a given XML file to YOLO format.\n",
    "\n",
    "    Input:  f      The path of the file to parse.\n",
    "\n",
    "    Output: A list of objects in YOLO format.\n",
    "            Each object is a list of numbers [class_id, x_center, y_center, width, height].\n",
    "    \"\"\"\n",
    "\n",
    "    objects = []\n",
    "\n",
    "    tree = ET.parse(f)\n",
    "    root = tree.getroot()\n",
    "    width = int(root.find(\"size\").find(\"width\").text)\n",
    "    height = int(root.find(\"size\").find(\"height\").text)\n",
    "\n",
    "    for obj in root.findall(\"object\"):\n",
    "        class_id = int(obj.find(\"name\").text)\n",
    "        bndbox = obj.find(\"bndbox\")\n",
    "        # Getting the bounding box values\n",
    "        x_c = ...\n",
    "        y_c = ...\n",
    "        width = ...\n",
    "        height = ...\n",
    "\n",
    "        # Appending the object in the form of\n",
    "        # [class_id, x_center, y_center, width, height]\n",
    "        objects.append(...)\n",
    "\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this working function, we can use one that takes the list of bounding box data and writes to disk a text file of the bounding box data.\n",
    "\n",
    "**Task 3.7.6:** Write the bounding box data as a text file for YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_label(objects, filename):\n",
    "    \"\"\"Write the annotations to a file in the YOLO text format.\n",
    "\n",
    "    Input:  objects   A list of YOLO objects, each a list of numbers.\n",
    "            filename  The path to write the text file.\"\"\"\n",
    "\n",
    "    with open(filename, \"w\") as f:\n",
    "        for obj in objects:\n",
    "            # Write the object out as space-separated values\n",
    "\n",
    "            # Write a newline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = parse_annotations(istanbul_dir / \"0ab6f274892b9b370e6441886b2d7b9d.xml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_label(objects, \"yolo_test.txt\")\n",
    "!head -n 1 yolo_test.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to set up our directory structure for YOLO.  Recall that YOLO expects a structure like\n",
    "```\n",
    "data_yolo\n",
    "├── images\n",
    "│   ├── train\n",
    "│   └── val\n",
    "└── labels\n",
    "    ├── train\n",
    "    └── val\n",
    "```\n",
    "We'll need to:\n",
    "- Create the directories.\n",
    "- Split the data into training and validation sets (80/20).\n",
    "- Copy images to the correct folders.\n",
    "- Convert the XML files to text files in the correct folders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3.7.7:** Set up the directory structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_base = Path(\"data_yolo\")\n",
    "# Make sure everything's cleared out\n",
    "shutil.rmtree(yolo_base, ignore_errors=True)\n",
    "\n",
    "# Make the directories\n",
    "...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3.7.8:** Populate the YOLO training directory. 80% of the data will be sent to `train` and the remaining 20% to `val`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't change this\n",
    "random.seed(42)\n",
    "\n",
    "train_frac = 0.8\n",
    "images = list(istanbul_dir.glob(\"*.jpg\"))\n",
    "\n",
    "for img in tqdm(images):\n",
    "    # Randomly choose train or val split\n",
    "    split = ... # this should be `train` or `val`\n",
    "    # XML file path, from image stem\n",
    "    annotation = istanbul_dir / f\"{img.stem}.xml\"\n",
    "    # Parse annotations.  Watch out for errors!\n",
    "    ...\n",
    "    \n",
    "    # Write label file based on parsed annotation\n",
    "    ...\n",
    "\n",
    "    \n",
    "    # Copy image file to correct location\n",
    "    shutil.copy(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this assignment, we'll load a pre-trained YOLO model, in order to reduce train times and make it more efficient. Nevertheless, it's important to understand how the training would be performed.\n",
    "\n",
    "The classes we wish to predict are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"bicycle\", \"bus\", \"car\", \"motorcycle\", \"person\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3.7.9:** Create a dictionary with the appropriate keys for a YOLO data set, for the creation of a YAML file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {\n",
    "    \"path\": str(\n",
    "        yolo_base.absolute()\n",
    "    ),  # It's easier to specify absolute paths with YOLO.\n",
    "    \"train\": ..., # Training images, relative to above.\n",
    "\n",
    "    \"val\": ..., # Validation images\n",
    "\n",
    "    \"names\": ..., # Class names, as a list\n",
    "    \n",
    "    \"nc\": ..., # Number of classes\n",
    "}\n",
    "\n",
    "print(metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3.7.10:** Save `metadata` as a YAML file named `data.yaml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_config = \"data.yaml\"\n",
    "yaml.safe_dump(...)\n",
    "\n",
    "!cat data.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the nano pre-trained YOLO model as our base model. Recall how this model is 30% smaller but with 80% of the performance of the small model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(\"yolov8n.pt\")\n",
    "\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3.7.11:** Load the pre-trained model for this assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = YOLO(...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3.7.12:** Define the variable `save_dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating our Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before using our model, let's evaluate how it performed. The results are saved in a directory as specified in the `.save_dir` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree $save_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3.7.13:** Display and examine the precision-recall curves for the model.  They are plotted in `PR_curve.png`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_curve_image = Image.open(...)\n",
    "pr_curve_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which classes does the model do well at detecting? Remember that the more area under the curve, the better the model is performing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run YOLO on Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confidently start using the YOLO model to detect objects in our images.\n",
    "\n",
    "**Task 3.7.14:** Detect the objects in image `istanbul_traffic/test/3c794894a576d0d6355379613c2dadc5.jpg`. Set the confidence to 50% and make sure to save the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path_task = ...\n",
    "\n",
    "result = ...\n",
    "\n",
    "print(type(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next thing we'd like to check is how many objects we detected.\n",
    "\n",
    "**Task 3.7.15:** Determine the number of objects we detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_detections = ...\n",
    "print(f\"Number of objects detected: {len(result[0].boxes.cls)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did we exactly detect?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3.7.16:** Create a dictionary that maps class names to how many objects we detected. E.g., how many \"cars\" we detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_objects = ...\n",
    "print(detected_objects)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOLO gain popularity because it's both fast and accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3.7.17:** Calculate the total time object detection took."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time = ...\n",
    "\n",
    "print(f\"Total time in milliseconds: {total_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have configured YOLO to save the image with the bounding boxes. Let's see how it did.\n",
    "\n",
    "**Task 3.7.18:** Create a path object with the location of the saved results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_of_results = ...\n",
    "print(f\"Location of saved results: {location_of_results}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the location of the saved results, we can take a look of the drawn bounding boxes from running YOLO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(location_of_results / \"3c794894a576d0d6355379613c2dadc5.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did we fair? If you are not satisfied with the results, what would you recommend?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3.7.19:** Run YOLO on all test images, `istanbul_traffic/test`. Set the confidence to 50% and save the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images_path = ...\n",
    "results_test = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By running YOLO on all our test images, we can determine the distribution of detected objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 3.7.20:** Create a dictionary that maps class names to how many objects we detected across all of the test images. E.g., how many \"cars\" we detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detected_objects_test = ...\n",
    "\n",
    "detected_objects_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are you surprised by this distribution? Or do they make sense given our images?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "This file &#169; 2024 by [WorldQuant University](https://www.wqu.edu/) is not licensed personal or commercial use of any kind. **Any downloading, reproduction or redistribution of this material is strictly prohibited.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "1d306f6bf6ee466f97fd0719d4d8e9a6": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "294172183c3a4c55903fcf326244da96": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4b4de5c731d1486891077910ef618b1f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "740e449697cd4fe9a6c228e39a1bea0b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "767595d4c991407bac4fc1488026feeb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "84794cbcd8dd40cca89a24e25d8e7a4f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_740e449697cd4fe9a6c228e39a1bea0b",
       "style": "IPY_MODEL_294172183c3a4c55903fcf326244da96",
       "value": " 5805/5805 [00:10&lt;00:00, 586.32it/s]"
      }
     },
     "84af8ddf2da24b539cc7a7b7fc5b36ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_e6928352db3647229e918884fd508582",
        "IPY_MODEL_8d91387c09504825becce37efd619fa2",
        "IPY_MODEL_84794cbcd8dd40cca89a24e25d8e7a4f"
       ],
       "layout": "IPY_MODEL_4b4de5c731d1486891077910ef618b1f"
      }
     },
     "8d91387c09504825becce37efd619fa2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_767595d4c991407bac4fc1488026feeb",
       "max": 5805,
       "style": "IPY_MODEL_1d306f6bf6ee466f97fd0719d4d8e9a6",
       "value": 5805
      }
     },
     "e6928352db3647229e918884fd508582": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_ec5bbdf3a67e4c87ad4195e3b0832549",
       "style": "IPY_MODEL_f4a09216dd73427d9007c8bb7d7597db",
       "value": "100%"
      }
     },
     "ec5bbdf3a67e4c87ad4195e3b0832549": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f4a09216dd73427d9007c8bb7d7597db": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
